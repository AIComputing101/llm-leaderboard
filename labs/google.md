# Google

**Total Models:** 28
**Public Models:** 8

## Models

| Model | Params | Architecture | ALScore | MMLU | GPQA | Released | Status |
|-------|--------|--------------|---------|------|------|----------|--------|
| [AudioPaLM](../models/google/audiopalm.md) | 340.0B | Dense | 3.7 | - | - | Jun/2023 | 🔴 |
| [PaLM 2](../models/google/palm-2.md) | 340.0B | Dense | 3.7 | - | - | May/2023 | 🟢 |
| [Switch](../models/google/switch.md) | 1600.0B | MoE | 3.2 | - | - | Jan/2021 | 🟢 |
| [Minerva](../models/google/minerva.md) | 540.0B | Dense | 2.2 | - | - | Jun/2022 | 🔴 |
| [U-PaLM](../models/google/u-palm.md) | 540.0B | Dense | 2.2 | 74.1 | - | Oct/2022 | 🔴 |
| [PaLM-Coder](../models/google/palm-coder.md) | 540.0B | Dense | 2.2 | - | - | Apr/2022 | 🔴 |
| [PaLM](../models/google/palm.md) | 540.0B | Dense | 2.2 | - | - | Apr/2022 | 🔴 |
| [Flan-PaLM](../models/google/flan-palm.md) | 540.0B | Dense | 2.2 | 73.5 | - | Oct/2022 | 🔴 |
| [UL2 20B](../models/google/ul2-20b.md) | 20.0B | Dense | 0.5 | 39.2 | - | May/2022 | 🔴 |
| [Meena](../models/google/meena.md) | 2.6B | Dense | 0.5 | - | - | Jan/2020 | 🔴 |
| [Flan-T5](../models/google/flan-t5.md) | 11.0B | Dense | 0.4 | - | - | Oct/2022 | 🟢 |
| [T5](../models/google/t5.md) | 11.0B | Dense | 0.3 | - | - | Oct/2019 | 🟢 |
| [TimesFM-ICF](../models/google/timesfm-icf.md) | 0.2B | Dense | 0.0 | - | - | Sep/2025 | 🔴 |
| [TimesFM](../models/google/timesfm.md) | 0.2B | Dense | 0.0 | - | - | Feb/2024 | 🟢 |
| [BERT](../models/google/bert.md) | 0.34B | Dense | 0.0 | - | - | Oct/2018 | 🟢 |
| [Transformer (big)](../models/google/transformer-big.md) | 0.213B | Dense | 0.0 | - | - | Jun/2017 | 🟢 |
| [Transformer (base)](../models/google/transformer-base.md) | 0.065B | Dense | 0.0 | - | - | Jun/2017 | 🟢 |
| [CoLT5](../models/google/colt5.md) | 5.2B | Dense | - | - | - | Mar/2023 | 🔴 |
| [RT-1](../models/google/rt-1.md) | 0.035B | Dense | - | - | - | Dec/2022 | 🔴 |
| [PaLI](../models/google/pali.md) | 17.0B | Dense | - | - | - | Sep/2022 | 🔴 |
| [‘monorepo-Transformer’](../models/google/monorepo-transformer.md) | 0.5B | Dense | - | - | - | Jul/2022 | 🔴 |
| [LIMoE](../models/google/limoe.md) | 5.6B | MoE | - | - | - | Jun/2022 | 🔴 |
| [LaMDA 2](../models/google/lamda-2.md) | 137.0B | Dense | - | - | - | May/2022 | 🟡 |
| [GLaM](../models/google/glam.md) | 1200.0B | MoE | - | - | - | Dec/2021 | 🔴 |
| [BERT-480](../models/google/bert-480.md) | 480.0B | Dense | - | - | - | Nov/2021 | 🔴 |
| [BERT-200](../models/google/bert-200.md) | 200.0B | Dense | - | - | - | Nov/2021 | 🔴 |
| [FLAN](../models/google/flan.md) | 137.0B | Dense | - | - | - | Sep/2021 | 🔴 |
| [LaMDA](../models/google/lamda.md) | 137.0B | Dense | - | - | - | Jun/2021 | 🔴 |

---

[← Back to Home](../README.md) • [View All Labs](../labs/)
