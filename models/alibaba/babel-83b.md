# Babel-83B

> Large Language Model

**Organization:** [Alibaba](../../labs/alibaba.md)
**Released:** Mar/2025
**Access:** 🟢 Public

---

## 📊 Overview

Babel-83B is a large language model developed by Alibaba.

## 🔧 Technical Specifications

### Model Architecture
- **Type:** Dense
- **Parameters:** 83.0B
- **Training Tokens:** 15000.0B
- **Token:Param Ratio:** 181:1 ✅ Compute-optimal

### Training Efficiency
- **ALScore:** 3.7 (Mid-tier)
- **Formula:** √(Parameters × Tokens) ÷ 300

### Training Data
- **Dataset Type:** synthetic, web-scale

## 📈 Performance Benchmarks

| Benchmark | Score | Description |
|-----------|-------|-------------|
| **MMLU** | - | General knowledge across 57 subjects |
| **MMLU-Pro** | - | Advanced MMLU variant |
| **GPQA** | - | Graduate-level reasoning |
| **HLE** | - | High-level evaluation |

## 🏷️ Model Tags

_No specific tags_

## 📝 Additional Notes

"top 25 languages by number of speakers, including English, Chinese, Hindi, Spanish, Arabic, French, Bengali, Portuguese, Russian, Urdu, Indonesian, German, Japanese, Swahili, Filipino, Tamil, Vietnamese, Turkish, Italian, Javanese, Korean, Hausa, Persian, Thai, and Burmese. These 25 languages support over 90% of the global population..."

## 🔗 Resources

- 🎮 [Try the Model](https://huggingface.co/Tower-Babel/Babel-83B)
- 📄 [Technical Documentation](https://arxiv.org/abs/2503.00865)

## 🔍 Related Models

**From Alibaba:**
- See all models in [Alibaba profile](../../labs/alibaba.md)

**Similar Architecture:**
- See all [Dense models](../../architectures/dense.md)

---

**Last Updated:** 2025-10-02

[← Back to Leaderboard](../../README.md) • [View All Alibaba Models](../../labs/alibaba.md)
